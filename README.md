<<<<<<< HEAD
# VisiÃ³n por Computador: QuantumViz

## ðŸ§  Trabajo03 â€” ClasificaciÃ³n de ImÃ¡genes MÃ©dicas (Descriptores ClÃ¡sicos vs Deep Learning)

---

### ðŸ“Œ Resumen

Este repositorio documenta, implementa y evalÃºa un pipeline completo para clasificaciÃ³n de radiografÃ­as de tÃ³rax (NORMAL vs PNEUMONIA) usando:

1. **Descriptores handcrafted** de forma y textura + clasificadores tradicionales (SVM, Random Forest, k-NN, Logistic Regression), y
2. **Redes Neuronales Convolucionales** (CNNs) entrenadas sobre imÃ¡genes.

El objetivo es explorar creativamente distintos descriptores, construir un flujo reproducible desde data raw hasta modelos finales, comparar desempeÃ±o y extraer conclusiones tÃ©cnicas.

---

### ðŸ“ Estructura del repositorio

```
proyecto-clasificacion-imagenes-medicas/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ processed/
â”‚   â”‚   â”œâ”€â”€ test/
â”‚   â”‚   â”‚   â”œâ”€â”€ NORMAL/
â”‚   â”‚   â”‚   â””â”€â”€ PNEUMONIA/
â”‚   â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”‚   â”œâ”€â”€ NORMAL/
â”‚   â”‚   â”‚   â””â”€â”€ PNEUMONIA/
â”‚   â”‚   â””â”€â”€ val/
â”‚   â”‚       â”œâ”€â”€ NORMAL/
â”‚   â”‚       â””â”€â”€ PNEUMONIA/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ chest_xray/
â”‚   â”‚       â”œâ”€â”€ test/
â”‚   â”‚       â”‚   â”œâ”€â”€ NORMAL/
â”‚   â”‚       â”‚   â””â”€â”€ PNEUMONIA/
â”‚   â”‚       â”œâ”€â”€ train/
â”‚   â”‚       â”‚   â”œâ”€â”€ NORMAL/
â”‚   â”‚       â”‚   â””â”€â”€ PNEUMONIA/
â”‚   â”‚       â””â”€â”€ val/
â”‚   â”‚           â”œâ”€â”€ NORMAL/
â”‚   â”‚           â””â”€â”€ PNEUMONIA/
â”‚   â””â”€â”€ person1946_bacteria_4875.jpeg
â”‚
â”œâ”€â”€ resultados/
â”‚   â”œâ”€â”€ descriptores_forma/
â”‚   â”‚   â”œâ”€â”€ figures/
â”‚   â”‚   â””â”€â”€ tables/
â”‚   â”œâ”€â”€ descriptores_textura/
â”‚   â”‚   â”œâ”€â”€ figures/
â”‚   â”‚   â””â”€â”€ tables/
â”‚   â”œâ”€â”€ exploracion/
â”‚   â”‚   â”œâ”€â”€ figures/
â”‚   â”‚   â””â”€â”€ tables/
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ best_chest_cnn.pth
â”‚       â”œâ”€â”€ figures/
â”‚       â””â”€â”€ tables/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ clasificacion/
â”‚   â”‚   â””â”€â”€ features_extract.py
â”‚   â”œâ”€â”€ descriptores_forma/
â”‚   â”‚   â”œâ”€â”€ contour_features.py
â”‚   â”‚   â”œâ”€â”€ fourier_descriptor.py
â”‚   â”‚   â”œâ”€â”€ hog_extractory.py
â”‚   â”‚   â””â”€â”€ hu_moments.py
â”‚   â”œâ”€â”€ descriptores_textura/
â”‚   â”‚   â”œâ”€â”€ texture_firstorder.py
â”‚   â”‚   â”œâ”€â”€ texture_gabor.py
â”‚   â”‚   â”œâ”€â”€ texture_glcm.py
â”‚   â”‚   â””â”€â”€ texture_lbp.py
â”‚   â”œâ”€â”€ parte_1/
â”‚   â”‚   â”œâ”€â”€ before_after.py
â”‚   â”‚   â””â”€â”€ preprocess_image.py
â”‚   â”œâ”€â”€ extract_selected.py
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ main.ipynb (Ãºnico notebook reproducible)
â”œâ”€â”€ README.md   # <- este archivo
â””â”€â”€ requirements.txt
```

---

### ðŸŽ¯ Objetivos especÃ­ficos

* Implementar pipelines para extracciÃ³n de descriptores de **forma** y **textura**.
* Entrenar y comparar clasificadores tradicionales usando las features handcrafted.
* Implementar y entrenar al menos una CNN para clasificaciÃ³n directa sobre imÃ¡genes.
* Evaluar y reportar mÃ©tricas: **Accuracy, Precision, Recall, F1, AUC-ROC**, matrices de confusiÃ³n y anÃ¡lisis de error.
* Entregar notebooks reproducibles, resultados y discusiÃ³n tÃ©cnica.

---

### ðŸ“¦ Datos

* El dataset base proviene de un conjunto pÃºblico de radiografÃ­as de tÃ³rax (casos NORMAL vs PNEUMONIA). Colocar los archivos raw en `data/raw/chest_xray/` respetando la particiÃ³n `train/ val/ test/`.
* `data/processed/` contiene las imÃ¡genes normalizadas y preprocesadas usadas por los scripts.

**Nota:** mantener `person1946_bacteria_4875.jpeg` (u otros ejemplos) en `data/` para pruebas rÃ¡pidas.

---

### ðŸ›  InstalaciÃ³n y entorno

Se recomienda usar un entorno virtual (conda o venv). A continuaciÃ³n instrucciones con `venv` (Windows / Linux / macOS).

```bash
python -m venv venv
# Windows (PowerShell)
# .\venv\Scripts\Activate.ps1
# Linux / macOS
source venv/bin/activate
pip install -r requirements.txt
```

`requirements.txt` incluye (ejemplos): `numpy, pandas, scikit-learn, matplotlib, opencv-python, scikit-image, torch, torchvision, tqdm`.

---

### ðŸš€ EjecuciÃ³n â€” Notebooks (recomendado)

Abrir `main.ipynb` o los notebooks de cada parte si los hay. De existir notebooks de cada parte:

* `notebooks/01_exploration.ipynb` â€” ExploraciÃ³n de datos y decisiones de preprocesamiento.
* `notebooks/02_features_extraction.ipynb` â€” ImplementaciÃ³n y visualizaciÃ³n de descriptores de forma y textura.
* `notebooks/03_classification_handcrafted.ipynb` â€” Entrenamiento y evaluaciÃ³n de clasificadores con features.
* `notebooks/04_cnn_training.ipynb` â€” Arquitectura y entrenamiento de la CNN.

**Nota:** Se decidiÃ³ realizar todo el proceso en un unico notebook `main.ipynb` por cuestiones de estructura.

Todos los notebooks (en este caso solo uno) registran figuras y mÃ©tricas en `resultados/` por defecto.

---

### ðŸ§­ Uso desde Python â€” API mÃ­nima

Ejemplos de import desde `src`:

```python
from src.clasificacion.features_extract import build_feature_matrix
from src.descriptores_forma.hog_extractory import extract_hog
from src.descriptores_textura.texture_lbp import extract_lbp
from src.parte_1.preprocess_image import preprocess_image
```
---

### ðŸ”¬ Preprocesamiento y parte 1 â€” Recomendaciones

1. **NormalizaciÃ³n de tamaÃ±o:** redimensionar a un tamaÃ±o fijo manteniendo relaciÃ³n de aspecto (p. ej. 224Ã—224 o 256Ã—256) segÃºn la red usada.
2. **EcualizaciÃ³n:** aplicar CLAHE local para mejorar contraste en radiografÃ­as.
3. **Denoising opcional:** filtros median o bilateral si hay ruido.
4. **SegmentaciÃ³n opcional:** para descriptores de forma, segmentar regiÃ³n pulmonar (umbral adaptativo, o U-Net entrenado si disponible).
5. **Augmentations (solo para CNN):** rotaciones pequeÃ±as, flips horizontales, cambios leves de brillo/contraste, pero evitar transformaciones que alteren la anatomÃ­a.

Guardad versiones originales y procesadas en `data/processed/`.

---

### ðŸ§© Descriptores implementados

Se recomienda como mÃ­nimo implementar 3 descriptores de forma y 3 de textura. Los mÃ³dulos en `src/descriptores_*` implementan estas funciones.

**Forma (ejemplos):**

* HOG (visualizaciÃ³n del descriptor y parÃ¡metros: cell_size, bins)
* Fourier Shape Descriptors (primeros N coeficientes del contorno)
* Momentos de Hu
* Contour features (Ã¡rea, perÃ­metro, circularidad, excentricidad)

**Textura (ejemplos):**

* LBP (histograma de patrones, experimentar radios y vecinos)
* GLCM (contraste, correlaciÃ³n, energÃ­a, homogeneidad â€” direcciones y distancias)
* Filtros de Gabor (estadÃ­sticas de respuestas)
* EstadÃ­sticas de primer orden (media, varianza, skewness, kurtosis, entropÃ­a)

Cada extractor debe documentarse (entrada, salida, shape) y tener tests bÃ¡sicos (por ejemplo: vector con longitud esperada, no NaNs).

---

### ðŸ“ˆ ClasificaciÃ³n y evaluaciÃ³n

#### Pipeline de features (handcrafted):

1. Extraer features para todo el dataset â†’ `X` (N Ã— D) y etiquetas `y`.
2. Normalizar features (StandardScaler o MinMax).
3. ReducciÃ³n dimensional (opcional): PCA, SelectKBest.
4. Entrenar clasificadores: SVM (lineal/RBF), RandomForest, k-NN, LogisticRegression.
5. ValidaciÃ³n: cross-validation estratificada y particiÃ³n `train/val/test`.
6. MÃ©tricas: Accuracy, Precision, Recall, F1, AUC, matriz de confusiÃ³n.

Generar reportes y comparar combinaciones de descriptores y clasificadores en `resultados/`.

#### Pipeline CNN (imagen â†’ etiqueta):

* Arquitectura base (ejemplo): ResNet18/Custom CNN.
* Entrenamiento con augmentations moderadas, criterio: CrossEntropyLoss.
* Callbacks: early stopping por validaciÃ³n, guardar `best_chest_cnn.pth`.
* Evaluar en split test final y comparar con aproximaciones handcrafted.

---

### ðŸ§ª ValidaciÃ³n sintÃ©tica y tests

* Crear casos sintÃ©ticos (rotaciones, escalados, ruido) para comprobar estabilidad de descriptores.
* Tests unitarios sugeridos en `tests/` (no incluidos por defecto, pero el lector puede incluirlos si asÃ­ lo desea):

  * `test_features_shape.py` (comprobar longitudes de vectores)
  * `test_preprocess.py` (salida esperada para una imagen de ejemplo)
  * `test_model_io.py` (guardar/cargar checkpoint)

---

### âš ï¸ Casos lÃ­mite y recomendaciones tÃ©cnicas

* **Desequilibrio:** usar tÃ©cnicas como oversampling, class weights o focal loss para CNN.
* **Pocas correspondencias (shape descriptors):** mejorar segmentaciÃ³n o usar descriptores globales.
* **RadiografÃ­as con artefactos:** aplicar preprocesamiento robusto (CLAHE + denoise).
* **EvaluaciÃ³n cuidadosa:** reportar desviaciÃ³n estÃ¡ndar en cross-validation.

---

### ðŸ§¾ Buenas prÃ¡cticas de reproducibilidad

* Registrar seeds (`numpy`, `torch`, `random`).
* Versionar `requirements.txt` y anotar la versiÃ³n de Python.
* Guardar hiperparÃ¡metros en `resultados/models/<exp_name>_hparams.json`.
* Documentar contribuciones por equipo en el reporte.

---

### ðŸ›  Issues conocidos / PrÃ³ximos pasos

* Consolidar tests automatizados.
* AÃ±adir un notebook que genere un benchmark comparativo final (tabla resumen y figuras).
* Experimentar con tÃ©cnicas de explainability (Grad-CAM) para la CNN.

---
=======
# VisionPorComputador-trabajo_03_v2
>>>>>>> fb8046cb2902f7e3f267f3acfde6ed6204fe4380
